---
categories:
- ""
- ""
date: "16th October 2021"
description: Test
draft: false
output:
image: LBS_campus.jpeg
keywords: ""
slug: aliquam
title: "Pre-programme Assignment: ggplot"
---

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset
library(here)
library(janitor)
```


## Introduction

Hi, I'm Leilah and I'm a [Masters in Financial Analysis](https://www.london.edu/masters-degrees/masters-in-financial-analysis?sc_camp=E6402B8ED1B34D3A80320FD55B304E23&gclid=CjwKCAjwvuGJBhB1EiwACU1AiS1xCI5yfkDtyowRPnV3LH9B4ZPTgQIKf9RNi38xfP7EVOvceTuMRxoCi2oQAvD_BwE&gclsrc=aw.ds) student at London Business School. Here I provide a extract of my first Data Analytics assignment at LBS, which provided an introduction to ggplot.


## Task 1: `gapminder` country comparison

The first task was to produce two graphs of how life expectancy has changed over the years using the `gapminder` dataset.

The `gapminder` dataset has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. First I glimpse the data and have a look at the first 20 rows.

```{r}
glimpse(gapminder)

head(gapminder, 20) # look at the first 20 rows of the dataframe

```

First I create the `country_data` and `continent_data`.

```{r}
country_data <- gapminder %>% 
            filter(country == "United Kingdom") 

continent_data <- gapminder %>% 
            filter(continent == "Europe")
```

Next I create a plot of life expectancy over time.

```{r, lifeExp_one_country}
plot1 <- ggplot(data = country_data, mapping = aes(x = year, y =lifeExp))+
          geom_point() +
          geom_smooth(se = FALSE)+
          NULL 

plot1
```

Then I add a title...

```{r, lifeExp_one_country_with_label}
plot1<- plot1 +
        labs(title = "UK Life Expectancy over time ",
              x = "Year",
              y = "Life Expectancy") +
        NULL

plot1
```

Next I produce a plot for all countries in the *continent*.

```{r lifeExp_one_continent}
ggplot(continent_data, mapping = aes(x = year , y = lifeExp , colour=country , group =country))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   NULL
```

Finally, using the original `gapminder` data, I produce a life expectancy over time graph, grouped (or faceted) by continent. I remove all legends, adding the `theme(legend.position="none")` in the end of our ggplot.

```{r lifeExp_facet_by_continent}
 ggplot(data = gapminder , mapping = aes(x = year, y = lifeExp, colour=country))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   facet_wrap(~continent) +
   theme(legend.position="none") + #remove all legends
   NULL
```


> Type your answer after this blockquote.

Life expectancy in the Americas, Asia, Europe and Oceania has generally increased over time, most likely due to technological advancements and improvements in the quality of healthcare. The picture for Africa, however, is more mixed. Some African countries show declining life expectancy post-1980, perhaps as a result of outbreaks of disease such as AIDS.

## Task 2: Brexit vote analysis

For the second task, I was asked to look at the results of the 2016 Brexit vote in the UK. First I read the data using `read_csv()` and glimpse it.

```{r load_brexit_data, warning=FALSE, message=FALSE}
brexit_results <- read_csv(here::here("data","brexit_results.csv"))


glimpse(brexit_results)
```

The data comes from [Elliott Morris](https://www.thecrosstab.com/), who cleaned it and made it available through his [DataCamp class on analysing election and polling data in R](https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r).

Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies).

To get a sense of the spread, or distribution, of the data, I plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5)+
  labs(
    title="Brexit Results",
    subtitle = "Histogram showing Proportion of votes in favour of Brexit",
    x = "Constituency leave share (%)",
    y = "Number of constituencies"
    )

# density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density()+
  labs(
    title="Brexit Results",
    subtitle = "Density of Proportion of votes in favour of Brexit",
    x = "Constituency leave share (%)",
    y = "Density"
    )


# The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)+
  labs(
    title="Brexit Results",
    subtitle = "Empirical CDF of Proportion of votes in favour of Brexit",
    x = "Constituency leave share (%)",
    y = "Empirical CDF"
    )
  


```

One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share`. To do this, let us get the correlation between the two variables

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor()
```

The correlation is almost 0.5, which shows that the two variables are positively correlated.

We can also create a scatterplot between these two variables using `geom_point`. We also add the best fit line, using `geom_smooth(method = "lm")`.

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method="lm" to get the best straight-line
  geom_smooth(method = "lm") + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  labs(
    title="Brexit Results",
    subtitle="Scatterplot of leave share against proportion of native-born residents",
    x="Proportion of native-born residents",
    y="Leave share"
    )+
  NULL
```

As the proportion of native-born residents increases, the proportion in favour of Brexit increases. 

## Task 3: Animal rescue incidents attended by the London Fire Brigade

The final task looked at animal rescue incidents attended by the London Fire Brigade.

[The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.

Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()


glimpse(animal_rescue)
```
One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)

```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

First I see how many incidents we have by animal group.

```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

Do you see anything strange in these tables?  
'Cat' and 'cat' are two separate entries.

Finally, I look at the notional cost for rescuing each of these animals. As the LFB says,

> Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

There is two things we will do:

1. Calculate the mean and median `incident_notional_cost` for each `animal_group_parent`
2. Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`.


Before we go on, however, we need to fix `incident_notional_cost` as it is stored as a `chr`, or character, rather than a number.

```{r, parse_incident_cost,message=FALSE, warning=FALSE}

# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost)

```

Now that incident_notional_cost is numeric, let us quickly calculate summary statistics for each animal group. 


```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```


Finally, I plot the distribution of incident_cost for each animal group.

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)



```



